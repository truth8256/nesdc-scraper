"""
summarize_pdf_pages.py
======================
PDFì˜ ê° í˜ì´ì§€ì—ì„œ ìƒë‹¨ í…ìŠ¤íŠ¸ì™€ í‘œ ì¼ë¶€ë¥¼ ìš”ì•½í•˜ì—¬ CSVë¡œ ì €ì¥.
ì‚¬ìš©ìê°€ Excelì—ì„œ Ctrl+Fë¡œ ê²€ìƒ‰í•˜ì—¬ ì›í•˜ëŠ” í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ìˆê²Œ í•¨.

Usage:
    python summarize_pdf_pages.py --id-range 15300 15322
    python summarize_pdf_pages.py --id-list 15310 15320 15330
"""

import os
import sys
import io
import warnings
import argparse
import pandas as pd
import pdfplumber

# UTF-8 ì¶œë ¥ ì„¤ì • (unbuffered)
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)

# ê²½ê³  ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore", message=".*gray non-stroke color.*")


def is_encoding_error(text: str, threshold=0.3) -> bool:
    """
    í…ìŠ¤íŠ¸ê°€ ì¸ì½”ë”© ì˜¤ë¥˜ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸.

    Parameters
    ----------
    text : str
        í™•ì¸í•  í…ìŠ¤íŠ¸
    threshold : float
        ì˜¤ë¥˜ ë¬¸ì ë¹„ìœ¨ ì„ê³„ê°’ (ê¸°ë³¸ 30%)

    Returns
    -------
    bool
        ì¸ì½”ë”© ì˜¤ë¥˜ ì—¬ë¶€
    """
    if not text or len(text) < 10:
        return False

    # ì¸ì½”ë”© ì˜¤ë¥˜ ì§€í‘œ: ï¿½, ï¿½, ê¹¨ì§„ ë¬¸ì ë“±
    error_chars = text.count('ï¿½') + text.count('ï¿½')

    # í•œê¸€ì´ ê±°ì˜ ì—†ê³  ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ìê°€ ë§ì€ ê²½ìš°
    # (ì •ìƒì ì¸ í•œê¸€ì€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„ 0xAC00-0xD7A3)
    korean_chars = sum(1 for c in text if 0xAC00 <= ord(c) <= 0xD7A3)
    total_chars = len([c for c in text if c.strip()])

    if total_chars == 0:
        return False

    # ì˜¤ë¥˜ ë¬¸ìê°€ ë§ê±°ë‚˜, í•œê¸€ì´ ê±°ì˜ ì—†ëŠ” ê²½ìš°
    error_ratio = error_chars / total_chars
    korean_ratio = korean_chars / total_chars if total_chars > 0 else 0

    # í•œê¸€ ë¬¸ì„œì¸ë° í•œê¸€ì´ 10% ë¯¸ë§Œì´ë©´ ì¸ì½”ë”© ì˜¤ë¥˜ë¡œ íŒë‹¨
    if error_ratio > threshold or (total_chars > 50 and korean_ratio < 0.1):
        return True

    return False


def get_target_pdf(dir_path: str) -> str:
    """í´ë”ì—ì„œ ê°€ì¥ í° PDF íŒŒì¼ ì°¾ê¸°."""
    if not os.path.exists(dir_path):
        return None

    pdfs = [
        os.path.join(dir_path, f)
        for f in os.listdir(dir_path)
        if f.lower().endswith(".pdf")
    ]

    if not pdfs:
        return None

    # ê°€ì¥ í° PDF ì„ íƒ
    return max(pdfs, key=os.path.getsize)


def summarize_pdf_pages(pdf_path, merge_tables=True, max_lines=5, max_table_rows=3):
    """
    PDF í•œ ê°œ íŒŒì¼ì˜ ê° í˜ì´ì§€ì—ì„œ ìƒë‹¨ í…ìŠ¤íŠ¸ì™€ í‘œ ì¼ë¶€ë¥¼ ìš”ì•½.

    Parameters
    ----------
    pdf_path : str
        ìš”ì•½í•  PDF íŒŒì¼ ê²½ë¡œ
    merge_tables : bool, default=True
        Trueë©´ í•œ í˜ì´ì§€ ë‚´ì˜ ëª¨ë“  í…Œì´ë¸”ì„ ë³‘í•©í•˜ì—¬ í•œ ë©ì–´ë¦¬ë¡œ ìš”ì•½.
        Falseë©´ ì²« ë²ˆì§¸ í…Œì´ë¸”ë§Œ ìš”ì•½.
    max_lines : int, default=5
        ê° í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜¬ ìµœëŒ€ ì¤„ ìˆ˜.
    max_table_rows : int, default=3
        ê° í…Œì´ë¸”(í˜¹ì€ ë³‘í•©ëœ í…Œì´ë¸”)ì—ì„œ ê°€ì ¸ì˜¬ ìµœëŒ€ í–‰ ìˆ˜.

    Returns
    -------
    list[dict]
        ê° í˜ì´ì§€ì˜ ìš”ì•½ ì •ë³´
    """
    summaries = []

    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages, 1):
            # â‘  í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = page.extract_text() or ""
            lines = [l.strip() for l in text.splitlines() if l.strip()]
            head_text = " / ".join(lines[:max_lines])

            # ì¸ì½”ë”© ì˜¤ë¥˜ ì²´í¬ ë° ëŒ€ì²´
            if is_encoding_error(head_text):
                head_text = "[ENCODING_ERROR] Text extraction failed due to encoding issues"

            # â‘¡ í…Œì´ë¸” ì¶”ì¶œ
            tables = page.extract_tables()
            table_text = ""

            if tables:
                merged = []
                if merge_tables:
                    # í˜ì´ì§€ ë‚´ ëª¨ë“  í…Œì´ë¸” ë³‘í•©
                    for t in tables:
                        merged.extend(t[:max_table_rows])
                else:
                    # ì²« ë²ˆì§¸ í…Œì´ë¸”ë§Œ
                    merged = tables[0][:max_table_rows]

                # ê° í–‰ì„ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´í™”
                table_text = " / ".join(
                    [
                        " | ".join([str(x) if x is not None else "" for x in row])
                        for row in merged
                        if any(row)
                    ]
                )

                # í…Œì´ë¸”ë„ ì¸ì½”ë”© ì˜¤ë¥˜ ì²´í¬
                if is_encoding_error(table_text):
                    table_text = "[ENCODING_ERROR] Table extraction failed due to encoding issues"

            # â‘¢ ìš”ì•½ ì €ì¥
            summaries.append({
                "page": i,
                "text_head": head_text[:400],   # í…ìŠ¤íŠ¸ ë„ˆë¬´ ê¸¸ë©´ ìë¦„
                "table_head": table_text[:400], # í…Œì´ë¸” ë‚´ìš©ë„ 400ì ì œí•œ
            })

    return summaries


def summarize_folders(
    base_folder,
    out_path="pdf_page_summary_all.csv",
    id_range=None,
    id_list=None,
):
    """
    base_folderì˜ í•˜ìœ„ í´ë”ë“¤ì„ ìˆœíšŒí•˜ë©°:
      - í´ë”ëª…ì´ ìˆ«ìì¸ ê²½ìš° id_rangeë‚˜ id_listë¡œ í•„í„°ë§ ê°€ëŠ¥
      - ê° í´ë”ì—ì„œ ê°€ì¥ í° PDF ì„ íƒ í›„ ìš”ì•½
      - í´ë”ëª…(id)ì„ ì²« ì—´ì— ê¸°ë¡

    Parameters
    ----------
    base_folder : str
        ìƒìœ„ í´ë” ê²½ë¡œ (ì˜ˆ: "data/raw")
    out_path : str
        ì¶œë ¥ CSV íŒŒì¼ëª…
    id_range : tuple[int, int], optional
        (start, end) ë²”ìœ„ë¡œ í•„í„°ë§
    id_list : list[int], optional
        íŠ¹ì • ID ë¦¬ìŠ¤íŠ¸ë¡œ í•„í„°ë§

    Returns
    -------
    pd.DataFrame
        ì „ì²´ ìš”ì•½ ê²°ê³¼
    """
    all_rows = []

    # ìˆœíšŒ ì‹œì‘
    folders = sorted(os.listdir(base_folder))

    for folder_name in folders:
        folder_path = os.path.join(base_folder, folder_name)
        if not os.path.isdir(folder_path):
            continue

        # í´ë”ëª…ì´ ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ê²½ìš°ë§Œ ì²˜ë¦¬
        try:
            folder_id = int(folder_name)
        except ValueError:
            continue

        # ë²”ìœ„ í˜¹ì€ ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
        if id_range:
            start, end = id_range
            if not (start <= folder_id <= end):
                continue
        if id_list and folder_id not in id_list:
            continue

        # PDF ì°¾ê¸°
        largest_pdf = get_target_pdf(folder_path)

        if not largest_pdf:
            print(f"âš ï¸  {folder_name}: PDF ì—†ìŒ")
            continue

        print(f"ğŸ“‚ {folder_name}: {os.path.basename(largest_pdf)}")

        try:
            summaries = summarize_pdf_pages(largest_pdf)
            for summary in summaries:
                summary["id"] = folder_name
                summary["pdf_name"] = os.path.basename(largest_pdf)
            all_rows.extend(summaries)
            print(f"   âœ… {len(summaries)} í˜ì´ì§€ ìš”ì•½ ì™„ë£Œ")
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")

    # ì €ì¥
    if all_rows:
        # ì—´ ìˆœì„œ: id, pdf_name, page, text_head, table_head
        df = pd.DataFrame(all_rows)
        df = df[["id", "pdf_name", "page", "text_head", "table_head"]]
        df.to_csv(out_path, index=False, encoding="utf-8-sig", escapechar='\\')
        print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {out_path}")
        print(f"ğŸ“Š ì´ {len(df)}ê°œ í˜ì´ì§€ ìš”ì•½")
        return df
    else:
        print("âŒ ì²˜ë¦¬í•  PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="PDF í˜ì´ì§€ ìš”ì•½ ìƒì„±")
    parser.add_argument(
        "--base-dir",
        default=None,
        help="PDFê°€ ìˆëŠ” ìƒìœ„ í´ë” (ê¸°ë³¸ê°’: script_dir/data/raw)"
    )
    parser.add_argument(
        "--output",
        default="pdf_page_summary.csv",
        help="ì¶œë ¥ CSV íŒŒì¼ëª… (ê¸°ë³¸ê°’: pdf_page_summary.csv)"
    )
    parser.add_argument(
        "--id-range",
        nargs=2,
        type=int,
        metavar=("START", "END"),
        help="í´ë” ID ë²”ìœ„ (ì˜ˆ: --id-range 15300 15322)"
    )
    parser.add_argument(
        "--id-list",
        nargs='+',
        type=int,
        help="íŠ¹ì • í´ë” ID ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: --id-list 15310 15320)"
    )

    args = parser.parse_args()

    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    if args.base_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        args.base_dir = os.path.join(script_dir, "data", "raw")

    print(f"ğŸ” ëŒ€ìƒ í´ë”: {args.base_dir}")

    if args.id_range:
        print(f"ğŸ“‹ ë²”ìœ„: {args.id_range[0]} ~ {args.id_range[1]}")
        id_range = tuple(args.id_range)
    else:
        id_range = None

    if args.id_list:
        print(f"ğŸ“‹ ID ë¦¬ìŠ¤íŠ¸: {args.id_list}")

    # ì‹¤í–‰
    df = summarize_folders(
        args.base_dir,
        out_path=args.output,
        id_range=id_range,
        id_list=args.id_list
    )

    if not df.empty:
        print(f"\nâœ¨ ì™„ë£Œ! {args.output} íŒŒì¼ì„ Excelë¡œ ì—´ì–´ì„œ ê²€ìƒ‰í•˜ì„¸ìš”.")
        print(f"   ì˜ˆ: Ctrl+Fë¡œ 'ì •ë‹¹ì§€ì§€ë„' ê²€ìƒ‰ â†’ í˜ì´ì§€ ë²ˆí˜¸ í™•ì¸")
